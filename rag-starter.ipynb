{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai.vocareum.com/v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model_name = 'gpt-3.5-turbo'\n",
    "llm = ChatOpenAI(model_name=model_name, temperature=0, max_tokens=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load reviews from tv-reviews.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load your documents\n",
    "# print(docs)\n",
    "\n",
    "loader = CSVLoader(file_path='./tv-reviews.csv')\n",
    "docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the documents you loaded into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use a Text Splitter to split the documents into chunks\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize your embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize your embeddings model\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize your vector db with your embeddings model and populate with your text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: populate your vector database with the chunks\n",
    "\n",
    "db = Chroma.from_documents(split_docs, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query your vector database for 5 most semantically similar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People liked the vibrant colors and crystal clear images of the picture quality. They were impressed by the sharpness and lifelike details, making everything look stunning and enhancing their viewing experience. The visuals were described as outstanding, with vivid colors and incredible detail, bringing every scene to life like a cinema experience.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    Based on the reviews in the context, tell me what people liked about the picture quality.\n",
    "    Make sure you do not paraphrase the reviews, and only use the information provided in the reviews.\n",
    "    \"\"\"\n",
    "# find top 5 semantically similar documents to the query\n",
    "\n",
    "use_chain_helper = False\n",
    "if use_chain_helper:\n",
    "    rag = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "    print(rag.run(query))\n",
    "else:\n",
    "    similar_docs = db.similarity_search(query, k=5)\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"{query}\\nContext: {context}\",\n",
    "        input_variables=[\"query\", \"context\"],\n",
    "    )\n",
    "    chain = load_qa_chain(llm, prompt = prompt, chain_type=\"stuff\")\n",
    "    print(chain.run(input_documents=similar_docs, query = query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined, they should provide enough information to answer our question about picture quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
